<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AlphaOmegaDarkLugiaGX</title>
  <style>
    body {
      background-color: black;
      font-family: 'Courier New', monospace;
      color: white;
    }
    #console {
      background-color: blue;
      padding: 20px;
      height: 100vh;
      overflow-y: scroll;
    }
    button {
      background-color: white;
      color: black;
      padding: 10px 20px;
      margin: 10px;
      cursor: pointer;
    }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/axios/dist/axios.min.js"></script>
</head>
<body>
  <div id="console"></div>
  <button id="recordButton">Record</button>
  <button id="pauseButton">Pause</button>

  <script>
    const recordButton = document.getElementById("recordButton");
    const pauseButton = document.getElementById("pauseButton");
    const consoleDiv = document.getElementById("console");

    let recognition;
    let isRecording = false;

    async function getSummary(text) {
      try {
        const response = await axios.post(
          "https://api.openai.com/v1/engines/davinci-codex/completions",
          {
            prompt: `Summarize the following text:\n\n${text}`,
            max_tokens: 50,
            n: 1,
            stop: null,
            temperature: 0.5,
          },
          {
            headers: {
              "Content-Type": "application/json",
              Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
            },
          }
        );

        const summary = response.data.choices[0].text.trim();
        return summary;
      } catch (error) {
        console.error("Error while getting summary:", error.response);
        return `Error while getting summary: ${JSON.stringify(error.response.data)}`;
      }
    }

    function startRecording() {
      recognition = new webkitSpeechRecognition();
      recognition.lang = "en-US";
      recognition.continuous = true;
      recognition.interimResults = true;

      recognition.onresult = (event) => {
        let transcript = event.results[event.results.length - 1][0].transcript;
        consoleDiv.innerHTML += transcript + '<br>';
      };

      recognition.onerror = (event) => {
        console.error('Error occurred in recognition:', event.error);
      };

      recognition.start();
      isRecording = true;
    }

    function stopRecording() {
      recognition.stop();
      isRecording = false;
    }

    recordButton.addEventListener('click', () => {
      if (!isRecording) {
        startRecording();
        consoleDiv.innerHTML += 'Recording...<br>';
      }
    });

    pauseButton.addEventListener('click', async () => {
      if (isRecording) {
        stopRecording();
        const transcript = consoleDiv.innerHTML;
        const summary = await getSummary(transcript);
        consoleDiv.innerHTML += `Summary: ${summary}<br>`;
      }
    });
  </script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
	<script>
		var scene = new THREE.Scene();
		var camera = new THREE.PerspectiveCamera(75, window.innerWidth/window.innerHeight, 0.1, 1000);
		var renderer = new THREE.WebGLRenderer();
		renderer.setSize(window.innerWidth, window.innerHeight);
		document.body.appendChild(renderer.domElement);

		var geometry = new THREE.BoxGeometry(1, 1, 1);
		var material = new THREE.MeshBasicMaterial({color: 0x00ff00});
		var cube = new THREE.Mesh(geometry, material);
		scene.add(cube);

		camera.position.z = 5;

		var animate = function () {
			requestAnimationFrame(animate);

			cube.rotation.x += 0.01;
			cube.rotation.y += 0.01;

			renderer.render(scene, camera);
		};

		animate();
	</script>
	<a href="new-page.html">Go to the new page</a>
</body>
</html>
